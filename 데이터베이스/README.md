# 데이터베이스 정리

## Relational Model
- 테이블 : relation
- 행 : tuple
- 열 : attribute
- 도메인(domain) : 각 열의 도메인은 해당 열에 허용된 값들의 집합
  - 모든 열의 도메인은 atomic -> 나눌 수 없는 값

#### Keys
- superkey(슈퍼 키)는 해당 값이 유일한 튜플을 식별할 수 있는 것\
- candidate key(후보 키)는 superkey들 중 값이 가장 적은 것 ex {ID} {ID, name} superkey들 중 {ID}가  candidate key
- candidate key들 중 하나를 선택하여 primary key(기본 키)가 될 수 있다.
- foreign key(외래 키) 제약 : 한 테이블의 값이 반드시 다른 테이블에서 나타나야 한다.

#### relational algebra
- Select: `𝜎` - 튜플(행) 선택
- Project: `Π` - 속성(열) 선택
- Union: `∪` - 합집합
- Set difference: `–` - 차집합
- Cartesian product: `×` - 테이블 조인 전체 곱을 나타냄
- Rename: `ρ`

- 내추럴 조인 : `⋈` - 두 릴레이션 R, S에 대해서 교집합인 원소들의 집합
- 세타 조인 : `⋈θ` - `R ⋈θ S = σθ(R × S)` 과 동일


## SQL Basics

#### create
create table r(a1 d1, a2 d2,
	(integrity-constraint)
)

#### integrity constraint
- primary key
- foreign key() references r
- not null

#### alter
- alter table r add A D -> 테이블 r 에 D 도메인인 A 어트리뷰트 추가
- alter table r drop A -> 테이블 r에 A 어트리뷰트 삭제

- 전형적인 SQL 쿼리
```
select A1, ... An
from r1, r2, ..., rm
where p
```
-> SQL 쿼리의 결과는 릴레이션

#### select 절
- 속성들을 뽑아냄
- 디폴트로 중복을 허용, 중복을 없애고 싶으면 distinct

#### where절
- 조건 명시

#### from 절
- 카티시안 프로덕트와 동일하다.

#### order by
- 순서를 지정할 수 있음
- 오름차순이 디폴트

#### group by
- 특정 속성에 대한 그룹으로 연산 수행

#### 중첩된 서브 쿼리
```
select distinct course_id
from section
where semester = ’Fall’ and year = 2009 and course_id in
  (select course_id
  from section
  where semester = ’Spring’ and year= 2010);
```


## Intermediate SQL

#### inner join
- 정확히 매치하는 튜플들만 포함시키는것

#### outer join
- 매치되지 않는 튜플도 포함시키는 것
- 매치되지 않는 속성은 null
- left outer join : 왼쪽 릴레이션의 튜플들은 모두 포함
- right outer join : 오른쪽 릴레이션의 튜플들 모두 포함
- full outer join : 왼쪽, 오른쪽 모두 포함

#### transaction
- 여러 SQL이 하나의 동작으로 이루어지는 것
- 전체 다 실행되거나(commit), 모두 실행되지 않아야 함(roll back)




## ER model
- entity : 다른 모든 객체들과 구별되는 사물
- entity들은 속성을 가진다 ex) 사람은 이름과 주소가 있다.
- entity set : 같은 속성을 공유하는 엔티티들의 집합
- domain : 각 속성들에 허락된 값들의 집합

#### 속성의 분류(유형)
- 단순 속성(simple attribute) - 복합 속성(composite attribute)
- 단일값 속성(single-valued attribute) - 다중값 속성(multivalued attribute)
- 유도 속성(derived attribute) - 저장 속성

#### 대응 카디널리티(mapping cardinality)
- 일대일(one to one)
- 일대다(one to many)
- 다대일(many to one)
- 다대다(many to many)

#### Keys
- super key : 엔티티 하나만을 식별할 수 있는 속성들의 집합
- candidate key : super key들 중 속성의 수가 가장 적은 키
- primary key : candidate key 중 선택된 키

- primary key의 조합으로 relationship의 super key를 만들 수 있다.
-> 엔티티 셋 둘의 조합에는 최대 한개의 relationship이 존재

## 트랜잭션 (Transaction)
- 하나의 논리적 기능을 수행하기 위한 작업 단위
- 여러 쿼리를 하나로 묶는 단위

### ACID 속성
- atomicity (원자성) : 트랜잭션이 모두 실행되거나, 실패할 경우 전부 실행 안되는것
- consistency (일관성) : 격리된 트랜잭션의 실행이 데이터베이스의 일관성을 보존해야함
- isolation (격리성) : 한 트랜잭션의 실행중 다른 트랜잭션이 끼지 못하도록 하는것
- durability (지속성) : 시스템에 crash가 발생하더라도 트랜잭션이 반영되어야하는것

- 격리성을 보장하는건 시스템 성능에 안 좋을 수 있음 - 약간 풀어줌

```
예시
A -> B 로 50달러 보내는 상황
transaction i
read(A)
A = A - 50
write(A)
read(B)
B = B + 50
write(B)
```

- 일관성 - A + B의 합이 트랜잭션이 끝나고 나서도 같아야함
- 원자성 - 중간에 실패(비일관적인 상태)하면 모두 되돌아가야함 -> 트랜잭션 중에는 일관성이 깨질 수도 있지만, 트랜잭션 전이나 후에는 일관적이여함 - 로그가 필요
- 지속성 - 트랜잭션이 성공했을때, 어떠한 시스템 장애가 생겨도 데이터 손실이 없어야함 - 트랜잭션 완료 이전에 디스크에 쓰거나, 디스크에 업데이트 정보를 먼저 써놓음 - 이러면 시스템 장애 후에도 복구 가능
- 격리성 - 만약 write(A) 상태에서 동시적으로 실행중인 트랜잭션이 A + B를 참조하면 비일관적인 값을 얻게됨 - 이를 해결하는게 격리성 - serial하게 동작하게 하면 가능은 하지만 동시성의 장점을 모두 잃음


### 트랜잭션 상태
- aborted - 성공적으로 트랜잭션이 완료되지 못한 상태
- roll back - aborted 상태에서 중간까지의 변화를 복구시키는 것
- roll back 은 보통 log를 통해 수행
- commited - 성공적으로 트랜잭션이 완료된 상태 - 시스템 장애가 발생해도 반드시 유지되어야함
한번 커밋된건 복구 불가능 - 복구하려면 compensating transaction 실행해야함

--------------------------------------------
- active : 트랜잭션이 실행중인 상태 - 그림 존재
- partially committed : 마지막 statement가 실행된 후의 상태
- failed : 실행이 더이상 되지 않음을 발견한 후의 상태
- aborted : roll back되고 트랜잭션 시작 이전 상태로 돌아간 상태
- committed : 성공적으로 트랜잭션이 마무리된 상태

### 트랜잭션 격리 수준
- 아래로 갈수록 낮은 격리
- serializable : 완벽히 격리되어 순차적으로만 실행 가능한 수준
- repeatable read : 커밋된 데이터만 읽을 수 있고, 한 트랜잭션이 읽는 동안에는 업데이트 불가능
- read committed : 커밋된 데이터만 읽을 수 있지만 읽는 동안 업데이트 가능
- read uncommitted : 커밋되지 않은 데이터도 읽을 수 있음
- 모든 단계에서 dirty write 를 허용하지 않음 - 이미 다른 트랜잭션에 의해 수정된 데이터를 또 쓰는게 불가능

### 무결성 (Integrity)
- 데이터의 정확성, 일관성, 유효성 유지하는 것
#### 종류
- 개체 무결성 : 기본키는 null 불가
- 참조 무결성 : 서로 참조인 관계인 테이블의 데이터는 항상 값이 일관되어야함
- 고유 무결성 : unique 조건이 주어진 경우 모두 고유한 값을 가져야함
- NULL 무결성 : NOT NULL 조건이 주어진 경우 해당 속성 값은 NULL 불가




## 정규화(Normalization)
- 존재 이유
	- 이상 현상(anomaly) 해결
	- 저장 공간 효율화
### 이상 현상 (Anomaly)
	- 갱신 이상 : 중복된 튜플들 중 하나만 갱신되어 나머지들은 아직 갱신 전 데이터를 유지하는 경우
	- 삭제 이상 : 필요한 데이터가 함께 삭제되는 것
	- 삽입 이상 : 하나의 필드 값이 NULL이 불가능하여 삽입이 안되는 경우
### 제 1정규형
- 모든 도메인이 atomic – 나눌 수 없어야함

|number|content|
|---------|-----------|
|1|a, b|
|2|c, d|

->  변화 후
|number|content|
|--------|--------|
|1|a|
|1|b|
|2|c|
|2|d|

### 제 2정규형
- 제 1정규형이면서 기본키가 아닌 모든 속성이 기본키에 완전 함수 종속적
- 1NF 이면서 복합 후보키가 없으면 자동으로 2 정규형

|이름|		기술|		근무지|
|----------|----------|-------------|
|A	|	B	|	서울|
|A	|	C	|	서울|
|A	|	D	|	서울|
|Z	|	X	|	경기도|

에서 {이름, 기술} 이 테이블의 기본키가 된다. 2 정규형을 만족하려면 기본키가 아닌 모든 속성이완전 함수 종속적이여야 한다. 즉, 이름, 기술 -> 근무지 여야 하는데 근무지는 사람 이름에만 종속적이다. 이름 -> 근무지 이므로 이는 2 정규형에 위배된다. 이를 분리하여

|이름|근무지| 
|-----------|------|
|A|서울|	
|Z|경기도|


|이름|기술|
|---|----------|
|A|B|
|A|C|
|A|D|
|Z|X|

라는 테이블로 나누면 왼쪽의 기본키는 {이름}, 오른쪽의 기본키는 {이름, 기술}이 된다. 따라서 2 정규형을 만족한다.

### 제 3정규형
- 2 정규형을 만족하고, 이행적 함수 종속이 없어야 함
- 이행적 함수 종속 : A -> B, B -> C 이면 A -> C 인것

|대회|우승|우승자 생년 월일|
|----|-----|--------|
|A|a|99.03.23|
|B|b|00.03.23|

의 경우 대회 -> 우승자 이고, 우승자 -> 생년 월일 이므로 대회 -> 생년 월일 이 성립하게 된다. 따라서 제 3정규형을 만족하지 않는다. 이를 분리하여 

|대회|우승자|	
|--|--|
|A|a|
|B|b|

|우승자|생년월일|
|-----|---------|
|a|99.03.23|
|b|00.03.23|

로 만들면 제 3정규형을 만족하게 된다.

### 보이스-코드 정규형 (BCNF)
- 제 3정규형을 만족함
- 결정자가 후보키가 아닌 함수 종속 제거

### 성능
- 정규형을 통해 테이블을 나눠도 성능은 좋아질수도 나빠질수도
- why? 테이블을 나누면 그만큼 조인을 해야 하는 경우가 많아지므로



## Indexing

##### 인덱싱의 존재 이유
- 많은 쿼리가 파일 내부의 레코드의 일부분만을 참조함
- 쿼리마다 모든 레코드를 가져오는건 비효율적

### 1. 기초 개념
인덱싱 : 책에서의 인덱스와 매우 비슷

#### 인덱싱 구현
- 기본 키로 정렬된 리스트를 유지하면서 인덱스를 구현하는건 비효율적
1. 인덱스 자체가 커짐
2. 검색 시간이 줄어들긴 하지만 그래도 많이 걸림
3. 업데이트 연산이 매우 비싸짐

#### 인덱스 기본 종류 2가지
1. ordered index : 값의 정렬된 순서에 기반하여 만듦
2. hash index : 버켓의 범위 안에 분포되어있는 값에 기반하여 만듦
- 검색 키 : 레코드를 검색하기 위해 사용되는 attribute의 집합







### 2. ordered index
- 인덱스 구조는 특정 검색 키와 관련되어 있음
- ordered index는 검색 키에 대해 정렬된 순서로 존재
- 클러스터링 인덱스 (프라이머리 인덱스) : 인덱스의 순서와 실제 파일의 정렬 순서가 같은 경우
- 보통 기본 키에 대한 인덱스인 경우가 많지만, 아닐 수도 있음
- 논클러스터링 인덱스 (세컨더리 인덱스) : 인덱스의 순서와 실제 파일의 정렬 순서가 다른 경우


#### 2.1 dense and sparse index
- 인덱스 레코드는 검색 키 값과 해당 블록에 대한 포인터로 이루어짐
- dense index : 인덱스 엔트리가 실제 파일 엔트리 전부를 가리킬 때 - 레코드 하나를 가리키게 됨
- sparse index : 인덱스 엔트리가 실제 파일 엔트리 일부만을 가리킬 때 - 블럭 단위로 가리키게 됨
- sparse index 는 전체를 가리키지 않으므로 반드시 프라이머리 인덱스여야함
- sparse index는 블럭을 찾아가서 offset으로 원하는 레코드를 찾음
- dense index가 더 빠르지만, 공간을 더 차지하고 삽입 삭제가 더 오버헤드가 큼

#### 2.2 멀티레벨 인덱스
- 만약 dense index를 1억개의 튜플이 있는 릴레이션에 만들면 백만개의 블록이 필요함
- 인덱스가 충분히 작아서 메인 메모리에 다 들어가지면 속도가 매우 향상됨
- outer는 프라이머리로, inner는 sparse로 구성
- I/O 횟수를 줄임으로써 속도가 향상됨

#### 2.3 인덱스 업데이트
- 레코드가 업데이트되면 인덱스 또한 업데이트 되어야함
- 싱글 레벨 인덱스 가정

##### 2.3.1 삽입

- dense index
1. 만약 검색 키가 인덱스에 없으면, 적절한 위치에 삽입
2. 만약 있으면
	- a. 만약 인덱스 엔트리가 모든 레코드를 가리키고 있다면, 새로운 엔트리에 대한 포인터를 인덱스 엔트리에 추가
	- b. 만약 인덱스 엔트리가 검색 키에 대한 첫번째 레코드만을 가리킨다면, 같은 키를 가진 다른 레코드 뒤에 추가
   
- sparse index
	- 인덱스가 각 블럭의 첫번째를 가리키므로, 만약 새 블럭을 만들었다면 첫번째 검색 키 값으로 삽입
	- 만약 새 레코드가 블럭 안에서 제일 작은 검색키보다도 더 작다면, 인덱스 엔트리를 수정
	- 만약 그렇지 않으면 아무런 변화 없음


##### 2.3.2 삭제

- dense index
1. 만약 삭제할 레코드가 유일한 검색키에 대한 레코드일때, 인덱스도 같이 삭제
2. 그렇지 않으면
  	- a. 만약 인덱스 엔트리가 같은 검색키에 대한 모든 포인터를 저장하는 형태라면, 인덱스 엔트리에서 해당 포인터를 삭제
  	- b. 만약 인덱스 엔트리가 검색 키에 대한 첫번째 레코드만을 가리키는 형태에서 삭제할 레코드가 첫번째 레코드라면 해당 인덱스가 다음 레코드를 가리키도록 업데이트

- sparse index
1. 만약 인덱스가 해당 검색 키를 가진 엔트리가 없다면, 아무 일도 안 일어남
2. 만약 그렇지 않다면
	- a. 만약 삭제된 레코드가 유일한 검색 키였다면, 다음 검색 키 값을 가리키도록 -> 만약 이미 가리키는게 있다면, 그 엔트리는 삭제됨
	- b. 만약 인덱스 엔트리가 삭제된 레코드를 가리키고 있었다면, 같은 검색 키값을 가진 다음 레코드를 가리키도록 업데이트








### 3. B+-Tree 인덱스 파일
- 루트에서 리프까지의 길이가 모두 같은 균형 트리 형태를 유지함

#### 3.1 B+-Tree의 구조
- 멀티 레벨 인덱스이지만, 멀티 레벨 index-sequential 파일하고는 조금 다름
- 노드 안의 검색 키들은 정렬되어있음
- 리프 노드 안의 포인터들은 실제 레코드를 가리킴
- 리프 노드 안의 마지막 포인터는 다음 리프 노드를 가리킴 - 순차 검색이 가능하도록
- 논리프 노드는 리프 노드에 대한 멀티 레벨 sparse 인덱스임
 

#### 3.2 업데이트
- 삽입 : 먼저 find() 를 통해 위치를 찾고, 거기에 삽입
- 삭제 : 먼저 find() 를 통해 삭제할 레코드의 위치를 찾고, 삭제한 후에 노드 안의 나머지들을 왼쪽으로 쉬프트






### 4. 해시 인덱스
- 검색 키를 해시 함수에 집어넣어 만든 해시 값이 버켓의 인덱스가 됨
- 버켓은 레코드들의 링크드 리스트로 구성
- 링크드 리스트로 구성하는것 - overflow chaining (closed addresssing)
- open addressing (ex linear probing) 방법은 삭제 시에 효율적이지 못해서 잘 쓰이지 않음
- 해시 인덱스는 범위 검색을 할 수 없음
- 한쪽 버켓에 레코드들이 쏠리는 skew 현상 발생 가능 - 좋은 해시 함수를 써야 하지만 완전히 극복은 불가능
- static hashing : 버켓의 수가 고정되어있는 형태 - 버켓의 수보다 레코드가 더 많아지면 검색에서 비효율적
- dynamic hashing : 만약 레코드 수가 버켓의 수의 두배가 되면, rebuilding -> 버켓의 수를 두배로












